{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from gaemain.ipynb\n",
      "importing Jupyter notebook from ram_mediapipe.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramba\\AppData\\Local\\Temp\\ipykernel_11140\\2195660888.py:22: DeprecationWarning: Please use `pearsonr` from the `scipy.stats` namespace, the `scipy.stats.stats` namespace is deprecated.\n",
      "  from scipy.stats.stats import pearsonr\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import optim\n",
    "import pandas as pd\n",
    "\n",
    "from gae.model import GCNModelVAE\n",
    "\n",
    "from gae.optimizer import loss_function\n",
    "from gae.utils import load_data, mask_test_edges, preprocess_graph, get_roc_score\n",
    "\n",
    "import import_ipynb\n",
    "from gaemain import gae_for\n",
    "\n",
    "from scipy.stats.stats import pearsonr  \n",
    "from scipy import spatial\n",
    "import os\n",
    "import glob\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "\treturn max(0.0, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing_latent_representation(dataset):\n",
    "    testSets=[]\n",
    "    personsPath=\"./datasets/\"+dataset+\"/\"\n",
    "    persons = os.listdir(personsPath)\n",
    "    for person in persons:\n",
    "        path=\"./datasets/\"+dataset+\"/\"+person+\"/test_image/\"\n",
    "        files=os.listdir(path)\n",
    "        count=0\n",
    "\n",
    "        cwd = os.getcwd()\n",
    "\n",
    "        try:\n",
    "            os.mkdir(cwd+\"./datasets/\"+dataset+\"/\"+person+\"/\"+person+\"_testing_latent_representation\")\n",
    "        except OSError as error:\n",
    "            # toDelete = cwd+\"/orl_dataset/person\"+str(person)+\"/person\"+str(person)+\"_testing_latent_representation\"\n",
    "            filestoDelete = glob.glob(cwd+\"./datasets/\"+dataset+\"/\"+person+\"/\"+person+\"_testing_latent_representation/*\")\n",
    "            for f in filestoDelete:\n",
    "                os.remove(f)\n",
    "\n",
    "        for image in files:\n",
    "            image_path=path+image\n",
    "            imageName=image.split(\".\")\n",
    "            # print(image_path)\n",
    "            count=count+1\n",
    "            Z=gae_for(image_path)\n",
    "            Z=Z.detach().numpy() #convert to Numpy array\n",
    "            Z = pd.DataFrame(Z) #convert to a dataframe\n",
    "            testSets.append(Z)\n",
    "            csv_path=\"./datasets/\"+dataset+\"/\"+person+\"/\"+person+\"_testing_latent_representation/\"+imageName[0]+\"_signature.csv\"\n",
    "            Z.to_csv(csv_path,index=False) #save to file\n",
    "        print(\"Latent representation of \",person,\" is completed\")\n",
    "    print(\"total \",len(testSets),\" test cases\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetching_testing_latent(dataset, ind, testSets, testPersonName):\n",
    "    personsPath=\"./datasets/\"+dataset+\"/\"\n",
    "    persons = os.listdir(personsPath)\n",
    "    for person in persons:\n",
    "        tests=glob.glob(\"./datasets/\"+dataset+\"/\"+person+\"/\"+person+\"_testing_latent_representation/*.csv\")\n",
    "        for test in tests: #for eacg file\n",
    "            personS=test\n",
    "            testSets.append(np.loadtxt(test,delimiter=','))  #sign[ind]= content of file, seperated by comma\n",
    "            testSets[ind]=testSets[ind][1:]\n",
    "            testPersonName.append(personS)\n",
    "            ind+=1\n",
    "    return testSets, testPersonName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def c_dist(dataset, testPersonName, testSets):  \n",
    "  acc=[]\n",
    "  avg_p=[]\n",
    "  avg_recall=[]\n",
    "  avg_fScore=[]\n",
    "  betaSquare=0.5*0.5\n",
    "  r_rate=0 #recognition rate\n",
    "  pr_rate=0 #recognition rate\n",
    "  acc=[]\n",
    "  sign=[]  #15*null\n",
    "  index=0\n",
    "  count=1\n",
    "\n",
    "  for testSet in testSets:\n",
    "    data = []\n",
    "    test=[]\n",
    "    TP=0\n",
    "    TN=0\n",
    "    FP=0\n",
    "    FN=0\n",
    "    tdata=testSet\n",
    "    dist=[]\n",
    "    pearson_dist=[]\n",
    "    cosine_dist=[]\n",
    "    c_dist=[]\n",
    "    orig_path=\"./datasets/\"+dataset+\"/\"\n",
    "    files=os.listdir(orig_path)\n",
    "    tests=[]\n",
    "    trainPersonName=[]\n",
    "    numberOfTrainedRepresentations=[]\n",
    "    for file in files: #for each person\n",
    "      tests=glob.glob(orig_path + file + '/' + file +'_training_latent_representation/*.csv')\n",
    "      numberOfTrainedRepresentations.append(len(tests))\n",
    "      numberOfTrainedRepresentations2=len(tests)\n",
    "      sign=[None]*15  #15*null\n",
    "      ind=0\n",
    "      for test in tests: #for eacg file\n",
    "        personS2=test\n",
    "        trainPersonName.append(personS2)\n",
    "        sign[ind]=np.loadtxt(test,delimiter=',')  #sign[ind]= content of file, seperated by comma\n",
    "        sign[ind]=sign[ind][1:]\n",
    "        ind+=1\n",
    "    # print(trainPersonName)\n",
    "      for ele in sign:\n",
    "        if ele is None:\n",
    "          break\n",
    "        c_dist.append(1/(1 + np.exp(-pearsonr(np.array(tdata).flatten() ,np.array(ele).flatten())[0])))\n",
    "\n",
    "    max_c_dist=c_dist.index(max(c_dist))\n",
    "    print(\"Test case: \",count)\n",
    "    count=count+1\n",
    "    # print(\"maximum c_dist=\",max(c_dist))\n",
    "    if(testPersonName[index].split(\"/\")[3] != trainPersonName[max_c_dist//numberOfTrainedRepresentations2].split(\"/\")[3]):\n",
    "      print(\"\\t\\t\\t\\tthis is wrong\")\n",
    "      TP=0\n",
    "      TN=13\n",
    "      FP=1\n",
    "      FP=1\n",
    "    elif(testPersonName[index].split(\"/\")[3] == trainPersonName[max_c_dist//numberOfTrainedRepresentations2].split(\"/\")[3]):\n",
    "      r_rate+=1\n",
    "      TP=1\n",
    "      TN=14\n",
    "      FN=0\n",
    "      FP=0\n",
    "\n",
    "    # print(\"Printing test images\")\n",
    "    print(\"test subject name: \", testPersonName[index].split(\"/\")[3])\n",
    "    path1=testPersonName[index].split(\"/\")[0]+\"/\"+testPersonName[index].split(\"/\")[1]+\"/\"+testPersonName[index].split(\"/\")[2]+\"/\"+testPersonName[index].split(\"/\")[3]+\"/test_image/\"\n",
    "    path2=testPersonName[index].split(\"\\\\\")[-1].split(\"_signature.csv\")[0]+\".jpg\"\n",
    "    path=path1+path2\n",
    "    # print(path1)\n",
    "    # print(path2)\n",
    "    image1 = mpimg.imread(path)\n",
    "\n",
    "    # print(\"printing matched image\")\n",
    "    print(\"Matched subject name: \", trainPersonName[max_c_dist//numberOfTrainedRepresentations2].split(\"/\")[3])\n",
    "    path3=trainPersonName[max_c_dist//numberOfTrainedRepresentations2 ].split(\"/\")[0]+\"/\"+trainPersonName[max_c_dist//numberOfTrainedRepresentations2 ].split(\"/\")[1]+\"/\"+trainPersonName[max_c_dist//numberOfTrainedRepresentations2 ].split(\"/\")[2]+\"/\"+trainPersonName[max_c_dist//numberOfTrainedRepresentations2 ].split(\"/\")[3]+\"/train_images/\"\n",
    "    path4=trainPersonName[max_c_dist//numberOfTrainedRepresentations2 ].split(\"\\\\\")[-1].split(\"_signature.csv\")[0]+\".jpg\"\n",
    "    path5=path3+path4\n",
    "    image2 = mpimg.imread(path5)\n",
    "\n",
    "    f, axarr = plt.subplots(1,2)\n",
    "    axarr[0].imshow(image1)\n",
    "    axarr[1].imshow(image2)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    Accuracy = (TP + TN )/ (TP + TN + FP + FN) #(all correct / all)\n",
    "    Misclassification = (FP + FN )/ (TP + TN + FP + FN) #(all incorrect / all)\n",
    "    Precision  = TP / (TP + FP) #(true positives / predicted positives)\n",
    "    deno=TP+FP\n",
    "    Sensitivity   = TP / (deno) #aka Recall (true positives / all actual positives)\n",
    "    Specificity  =TN / (TN + FP) #(true negatives / all actual negatives)\n",
    "    F1_deno=(Precision+Sensitivity)\n",
    "    if(F1_deno==0):\n",
    "      F1_Score=0\n",
    "    else:\n",
    "      F1_Score=(1+betaSquare)*((Precision*Sensitivity)/(betaSquare*F1_deno))\n",
    "    acc.append(Accuracy)\n",
    "    avg_p.append(Precision)\n",
    "    avg_recall.append(Sensitivity)\n",
    "    avg_fScore.append(F1_Score)\n",
    "    index=index+1\n",
    "  # print(r_rate)\n",
    "  # print(\"Total Test Case: {}\\nAverage Accuracy: {}\\nRecognition Rate: {}\\nAverage Precision: {}\\nAverage Recall: {}\\nAverage F0.5 Score: {}\".format(len(acc),(sum(acc)/len(acc)),r_rate/len(acc),(sum(avg_p)/len(avg_p)),(sum(avg_recall)/len(avg_recall)),(sum(avg_fScore)/len(avg_fScore))))  \n",
    "  return(len(acc),(sum(acc)/len(acc)),r_rate/len(acc),(sum(avg_p)/len(avg_p)),(sum(avg_recall)/len(avg_recall)),(sum(avg_fScore)/len(avg_fScore)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_dist(dataset, testPersonName, testSets):\n",
    "  acc=[]\n",
    "  avg_p=[]\n",
    "  avg_recall=[]\n",
    "  avg_fScore=[]\n",
    "  betaSquare=0.5*0.5\n",
    "  r_rate=0 #recognition rate\n",
    "  pr_rate=0 #recognition rate\n",
    "  acc=[]\n",
    "  sign=[]  #15*null\n",
    "  index=0\n",
    "  count=1\n",
    "\n",
    "  for testSet in testSets:\n",
    "    data = []\n",
    "    test=[]\n",
    "    TP=0\n",
    "    TN=0\n",
    "    FP=0\n",
    "    FN=0\n",
    "    tdata=testSet\n",
    "    dist=[]\n",
    "    pearson_dist=[]\n",
    "    cosine_dist=[]\n",
    "    c_dist=[]\n",
    "    orig_path=\"./datasets/\"+dataset+\"/\"\n",
    "    files=os.listdir(orig_path)\n",
    "    tests=[]\n",
    "    trainPersonName=[]\n",
    "    numberOfTrainedRepresentations=[]\n",
    "    for file in files: #for each person\n",
    "      tests=glob.glob(orig_path + file + '/' + file +'_training_latent_representation/*.csv')\n",
    "      numberOfTrainedRepresentations.append(len(tests))\n",
    "      numberOfTrainedRepresentations2=len(tests)\n",
    "      sign=[None]*15  #15*null\n",
    "      ind=0\n",
    "      for test in tests: #for eacg file\n",
    "        personS2=test\n",
    "        trainPersonName.append(personS2)\n",
    "        sign[ind]=np.loadtxt(test,delimiter=',')  #sign[ind]= content of file, seperated by comma\n",
    "        sign[ind]=sign[ind][1:]\n",
    "        ind+=1\n",
    "\n",
    "      for ele in sign:\n",
    "        if ele is None:\n",
    "          break\n",
    "        cosine_dist.append(relu((1 - spatial.distance.cosine(np.array(tdata).flatten() ,np.array(ele).flatten()))))\n",
    "\n",
    "    max_cosine=cosine_dist.index(max(cosine_dist))\n",
    "    print(\"Cosine distance of all comparisons: \",cosine_dist)\n",
    "    count=count+1\n",
    "    print(\"maximum max_cosine=\",max(cosine_dist))\n",
    "    \n",
    "    if(testPersonName[index].split(\"/\")[3] != trainPersonName[max_cosine//numberOfTrainedRepresentations2].split(\"/\")[3]):\n",
    "      # print(\"\\t\\t\\t\\tthis is wrong\")\n",
    "      TP=0\n",
    "      TN=13\n",
    "      FP=1\n",
    "      FP=1\n",
    "    elif(testPersonName[index].split(\"/\")[3] == trainPersonName[max_cosine//numberOfTrainedRepresentations2].split(\"/\")[3]):\n",
    "      r_rate+=1\n",
    "      TP=1\n",
    "      TN=14\n",
    "      FN=0\n",
    "      FP=0\n",
    "\n",
    "    # print(\"Printing test images\")\n",
    "    print(\"test subject name: \", testPersonName[index].split(\"/\")[3])\n",
    "    path1=testPersonName[index].split(\"/\")[0]+\"/\"+testPersonName[index].split(\"/\")[1]+\"/\"+testPersonName[index].split(\"/\")[2]+\"/\"+testPersonName[index].split(\"/\")[3]+\"/test_image/\"\n",
    "    path2=testPersonName[index].split(\"\\\\\")[-1].split(\"_signature.csv\")[0]+\".jpg\"\n",
    "    path=path1+path2\n",
    "    # print(path1)\n",
    "    # print(path2)\n",
    "    image1 = mpimg.imread(path)\n",
    "\n",
    "    # print(\"printing matched image\")\n",
    "    print(\"Matched subject name: \", trainPersonName[max_cosine//numberOfTrainedRepresentations2].split(\"/\")[3])\n",
    "    path3=trainPersonName[max_cosine//numberOfTrainedRepresentations2 ].split(\"/\")[0]+\"/\"+trainPersonName[max_cosine//numberOfTrainedRepresentations2 ].split(\"/\")[1]+\"/\"+trainPersonName[max_cosine//numberOfTrainedRepresentations2 ].split(\"/\")[2]+\"/\"+trainPersonName[max_cosine//numberOfTrainedRepresentations2 ].split(\"/\")[3]+\"/train_images/\"\n",
    "    path4=trainPersonName[max_cosine//numberOfTrainedRepresentations2 ].split(\"\\\\\")[-1].split(\"_signature.csv\")[0]+\".jpg\"\n",
    "    path5=path3+path4\n",
    "    image2 = mpimg.imread(path5)\n",
    "\n",
    "    f, axarr = plt.subplots(1,2)\n",
    "    axarr[0].imshow(image1)\n",
    "    axarr[1].imshow(image2)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    #Measures\n",
    "\n",
    "    Accuracy = (TP + TN )/ (TP + TN + FP + FN) #(all correct / all)\n",
    "    Misclassification = (FP + FN )/ (TP + TN + FP + FN) #(all incorrect / all)\n",
    "    Precision  = TP / (TP + FP) #(true positives / predicted positives)\n",
    "    deno=TP+FP\n",
    "    Sensitivity   = TP / (deno) #aka Recall (true positives / all actual positives)\n",
    "    Specificity  =TN / (TN + FP) #(true negatives / all actual negatives)\n",
    "    F1_deno=(Precision+Sensitivity)\n",
    "    if(F1_deno==0):\n",
    "      F1_Score=0\n",
    "    else:\n",
    "      F1_Score=(1+betaSquare)*((Precision*Sensitivity)/(betaSquare*F1_deno))\n",
    "    acc.append(Accuracy)\n",
    "    avg_p.append(Precision)\n",
    "    avg_recall.append(Sensitivity)\n",
    "    avg_fScore.append(F1_Score)\n",
    "    index=index+1\n",
    "  # print(r_rate)\n",
    "  # print(\"Total Test Case: {}\\nAverage Accuracy: {}\\nRecognition Rate: {}\\nAverage Precision: {}\\nAverage Recall: {}\\nAverage F0.5 Score: {}\".format(len(acc),(sum(acc)/len(acc)),r_rate/len(acc),(sum(avg_p)/len(avg_p)),(sum(avg_recall)/len(avg_recall)),(sum(avg_fScore)/len(avg_fScore))))\n",
    "  return(len(acc),(sum(acc)/len(acc)),r_rate/len(acc),(sum(avg_p)/len(avg_p)),(sum(avg_recall)/len(avg_recall)),(sum(avg_fScore)/len(avg_fScore)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearson_dist(dataset, testPersonName, testSets):\n",
    "  # Pearson\n",
    "  acc=[]\n",
    "  avg_p=[]\n",
    "  avg_recall=[]\n",
    "  avg_fScore=[]\n",
    "  betaSquare=0.5*0.5\n",
    "  r_rate=0 #recognition rate\n",
    "  pr_rate=0 #recognition rate\n",
    "  acc=[]\n",
    "  sign=[]  #15*null\n",
    "  index=0\n",
    "  count=1\n",
    "\n",
    "  for testSet in testSets:\n",
    "    data = []\n",
    "    test=[]\n",
    "    TP=0\n",
    "    TN=0\n",
    "    FP=0\n",
    "    FN=0\n",
    "    tdata=testSet\n",
    "    dist=[]\n",
    "    pearson_dist=[]\n",
    "    cosine_dist=[]\n",
    "    c_dist=[]\n",
    "    orig_path=\"./datasets/\"+dataset+\"/\"\n",
    "    files=os.listdir(orig_path)\n",
    "    tests=[]\n",
    "    trainPersonName=[]\n",
    "    numberOfTrainedRepresentations=[]\n",
    "    for file in files: #for each person\n",
    "      tests=glob.glob(orig_path + file + '/' + file +'_training_latent_representation/*.csv')\n",
    "      numberOfTrainedRepresentations.append(len(tests))\n",
    "      numberOfTrainedRepresentations2=len(tests)\n",
    "      sign=[None]*15  #15*null\n",
    "      ind=0\n",
    "      for test in tests: #for eacg file\n",
    "        personS2=test\n",
    "        trainPersonName.append(personS2)\n",
    "        sign[ind]=np.loadtxt(test,delimiter=',')  #sign[ind]= content of file, seperated by comma\n",
    "        sign[ind]=sign[ind][1:]\n",
    "        ind+=1\n",
    "\n",
    "      for ele in sign:\n",
    "        if ele is None:\n",
    "          break\n",
    "        pearson_dist.append(1/(1 + np.exp(-(pearsonr(np.array(tdata).flatten() ,np.array(ele).flatten())[0]))))\n",
    "\n",
    "    max_ind=pearson_dist.index(max(pearson_dist))\n",
    "    # print(\"Test case: \",count)\n",
    "    count=count+1\n",
    "    # print(\"maximum max_ind=\",max_ind)\n",
    "    \n",
    "    if(testPersonName[index].split(\"/\")[3] != trainPersonName[max_ind//numberOfTrainedRepresentations2].split(\"/\")[3]):\n",
    "      # print(\"\\t\\t\\t\\tthis is wrong\")\n",
    "      TP=0\n",
    "      TN=13\n",
    "      FP=1\n",
    "      FP=1\n",
    "    elif(testPersonName[index].split(\"/\")[3] == trainPersonName[max_ind//numberOfTrainedRepresentations2].split(\"/\")[3]):\n",
    "      r_rate+=1\n",
    "      TP=1\n",
    "      TN=14\n",
    "      FN=0\n",
    "      FP=0\n",
    "\n",
    "    # print(\"Printing test images\")\n",
    "    # print(\"test subject name: \", testPersonName[index].split(\"\\\\\")[-1:][0].split(\"_\")[0].split(\".\")[0])\n",
    "    # path1=testPersonName[index].split(\"/\")[0]+\"/\"+testPersonName[index].split(\"/\")[1]+\"/\"+testPersonName[index].split(\"/\")[2]+\"/\"+testPersonName[index].split(\"/\")[3]+\"/test_image/\"\n",
    "    # path2=testPersonName[index].split(\"\\\\\")[-1].split(\"_signature.csv\")[0]+\".jpg\"\n",
    "    # path=path1+path2\n",
    "    # image = mpimg.imread(path)\n",
    "    # plt.imshow(image)\n",
    "    # plt.show()\n",
    "\n",
    "    # print(\"printing matched image\")\n",
    "    # print(\"Matched subject name: \", trainPersonName[max_ind//numberOfTrainedRepresentations2 ].split(\"\\\\\")[-1:][0].split(\"_\")[0].split(\".\")[0])\n",
    "    # path3=trainPersonName[max_ind//numberOfTrainedRepresentations2 ].split(\"/\")[0]+\"/\"+trainPersonName[max_ind//numberOfTrainedRepresentations2 ].split(\"/\")[1]+\"/\"+trainPersonName[max_ind//numberOfTrainedRepresentations2 ].split(\"/\")[2]+\"/\"+trainPersonName[max_ind//numberOfTrainedRepresentations2 ].split(\"/\")[3]+\"/train_images/\"\n",
    "    # path4=trainPersonName[max_ind//numberOfTrainedRepresentations2 ].split(\"\\\\\")[-1].split(\"_signature.csv\")[0]+\".jpg\"\n",
    "    # path5=path3+path4\n",
    "    # image = mpimg.imread(path5)\n",
    "    # plt.imshow(image)\n",
    "    # plt.show()\n",
    "    #Measures\n",
    "\n",
    "    Accuracy = (TP + TN )/ (TP + TN + FP + FN) #(all correct / all)\n",
    "    Misclassification = (FP + FN )/ (TP + TN + FP + FN) #(all incorrect / all)\n",
    "    Precision  = TP / (TP + FP) #(true positives / predicted positives)\n",
    "    deno=TP+FP\n",
    "    Sensitivity   = TP / (deno) #aka Recall (true positives / all actual positives)\n",
    "    Specificity  =TN / (TN + FP) #(true negatives / all actual negatives)\n",
    "    F1_deno=(Precision+Sensitivity)\n",
    "    if(F1_deno==0):\n",
    "      F1_Score=0\n",
    "    else:\n",
    "      F1_Score=(1+betaSquare)*((Precision*Sensitivity)/(betaSquare*F1_deno))\n",
    "    acc.append(Accuracy)\n",
    "    avg_p.append(Precision)\n",
    "    avg_recall.append(Sensitivity)\n",
    "    avg_fScore.append(F1_Score)\n",
    "    index=index+1\n",
    "  # print(r_rate)\n",
    "  # print(\"Total Test Case: {}\\nAverage Accuracy: {}\\nRecognition Rate: {}\\nAverage Precision: {}\\nAverage Recall: {}\\nAverage F0.5 Score: {}\".format(len(acc),(sum(acc)/len(acc)),r_rate/len(acc),(sum(avg_p)/len(avg_p)),(sum(avg_recall)/len(avg_recall)),(sum(avg_fScore)/len(avg_fScore))))\n",
    "  return(len(acc),(sum(acc)/len(acc)),r_rate/len(acc),(sum(avg_p)/len(avg_p)),(sum(avg_recall)/len(avg_recall)),(sum(avg_fScore)/len(avg_fScore)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_controller(dataset):\n",
    "    global testSets\n",
    "    testSets=[]\n",
    "    ind=0\n",
    "    global testPersonName\n",
    "    testPersonName=[]\n",
    "    testing_latent_representation(dataset)\n",
    "    testSets, testPersonName=fetching_testing_latent(dataset, ind, testSets, testPersonName)\n",
    "    # print(testPersonName)\n",
    "    # print(testPersonName)\n",
    "    # c_dist_report = c_dist(dataset, testPersonName, testSets)\n",
    "    cosine_report = cosine_dist(dataset, testPersonName, testSets)\n",
    "    pearson_report = pearson_dist(dataset, testPersonName, testSets)\n",
    "    return cosine_report, pearson_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(test_controller(\"orl_dataset\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f86ed6d2ccfca78b79da216d0cb38b107327236eab96f22d38fd0505e1d75fcf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
